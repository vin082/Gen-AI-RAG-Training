{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic RAG with LangChain: Complete Guide\n",
    "\n",
    "## What is Agentic RAG?\n",
    "\n",
    "**Agentic RAG** combines Retrieval-Augmented Generation (RAG) with autonomous agents that can:\n",
    "- **Decide** which tools to use based on the query\n",
    "- **Reason** about the best approach to answer questions\n",
    "- **Combine** multiple information sources (vector databases, web search, APIs)\n",
    "- **Plan** multi-step operations to solve complex queries\n",
    "\n",
    "### Traditional RAG vs Agentic RAG\n",
    "\n",
    "| Traditional RAG | Agentic RAG |\n",
    "|----------------|-------------|\n",
    "| Single retrieval path | Multiple tool options |\n",
    "| No reasoning about source | Intelligently selects best source |\n",
    "| Static workflow | Dynamic decision-making |\n",
    "| Limited to vector DB | Can use web search, APIs, calculators, etc. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Dependencies\n",
    "\n",
    "Install required packages for this demonstration:\n",
    "```bash\n",
    "pip install langchain langchain-openai langchain-community langgraph chromadb tavily-python\n",
    "```\n",
    "\n",
    "**Note:** This notebook uses the **latest LangChain v1 API** with `create_agent`, which is built on top of LangGraph for better reliability and simpler interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All dependencies imported successfully!\n",
      "ğŸ“¦ Using LangChain v1 API with create_agent\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LangChain core imports (v1 API)\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.documents import Document\n",
    "from langchain.tools import tool\n",
    "\n",
    "# NEW: LangChain v1 agent API\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Verify API keys are loaded\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    raise ValueError(\"OPENAI_API_KEY not found in environment variables\")\n",
    "if not os.getenv(\"TAVILY_API_KEY\"):\n",
    "    raise ValueError(\"TAVILY_API_KEY not found in environment variables\")\n",
    "\n",
    "print(\"âœ… All dependencies imported successfully!\")\n",
    "print(\"ğŸ“¦ Using LangChain v1 API with create_agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create Sample Documents and Vector Database\n",
    "\n",
    "We'll create a knowledge base about **AI and Machine Learning concepts** using ChromaDB.\n",
    "\n",
    "### Why ChromaDB?\n",
    "- Lightweight and easy to use\n",
    "- Persistent storage option\n",
    "- Fast similarity search\n",
    "- Perfect for local development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“š Created 5 sample documents\n"
     ]
    }
   ],
   "source": [
    "# Create sample documents for our knowledge base\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"\"\"LangChain is a framework for developing applications powered by language models. \n",
    "        It enables applications that are context-aware and can reason. LangChain provides standard, \n",
    "        extendable interfaces and integrations for various components like model I/O, retrieval, \n",
    "        agents, and memory. The framework was created by Harrison Chase and launched in October 2022.\"\"\",\n",
    "        metadata={\"source\": \"langchain_docs\", \"topic\": \"framework\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"\"\"Retrieval-Augmented Generation (RAG) is a technique that combines the power of \n",
    "        large language models with external knowledge retrieval. It works by first retrieving relevant \n",
    "        documents from a knowledge base, then using those documents as context for the LLM to generate \n",
    "        an answer. This approach reduces hallucinations and provides more accurate, grounded responses.\"\"\",\n",
    "        metadata={\"source\": \"ai_concepts\", \"topic\": \"rag\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"\"\"Vector databases store data as high-dimensional vectors, which are mathematical \n",
    "        representations of data features. They enable semantic search by finding similar vectors using \n",
    "        distance metrics like cosine similarity. Popular vector databases include Chroma, Pinecone, \n",
    "        Weaviate, and Qdrant. These databases are essential for building RAG applications.\"\"\",\n",
    "        metadata={\"source\": \"ai_concepts\", \"topic\": \"vector_db\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"\"\"LangChain agents are systems that use a language model as a reasoning engine to \n",
    "        determine which actions to take and in what order. Agents have access to tools (like search engines, \n",
    "        calculators, or databases) and can dynamically decide which tool to use based on the user's input. \n",
    "        The agent follows a reasoning loop: Thought -> Action -> Observation -> repeat until done.\"\"\",\n",
    "        metadata={\"source\": \"langchain_docs\", \"topic\": \"agents\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"\"\"GPT-4 is OpenAI's fourth-generation language model, released in March 2023. \n",
    "        It's a multimodal model that can accept both image and text inputs and produce text outputs. \n",
    "        GPT-4 exhibits human-level performance on various professional and academic benchmarks. \n",
    "        It has improved reasoning capabilities and reduced hallucinations compared to GPT-3.5.\"\"\",\n",
    "        metadata={\"source\": \"ai_models\", \"topic\": \"gpt4\"}\n",
    "    )\n",
    "]\n",
    "\n",
    "print(f\"ğŸ“š Created {len(documents)} sample documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ Split into 5 chunks\n"
     ]
    }
   ],
   "source": [
    "# Split documents into smaller chunks for better retrieval\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "splits = text_splitter.split_documents(documents)\n",
    "print(f\"ğŸ“„ Split into {len(splits)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Vector database created successfully!\n",
      "ğŸ“Š Collection contains 25 vectors\n"
     ]
    }
   ],
   "source": [
    "# Create embeddings and vector store\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Create Chroma vector database\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"agentic_rag_demo\",\n",
    "    persist_directory=\"./chroma_agentic_rag\"\n",
    ")\n",
    "\n",
    "print(\"âœ… Vector database created successfully!\")\n",
    "print(f\"ğŸ“Š Collection contains {vectorstore._collection.count()} vectors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create Tools for the Agent\n",
    "\n",
    "### Tool 1: Retriever Tool\n",
    "Searches through our local knowledge base (vector database) for relevant information.\n",
    "\n",
    "### Tool 2: Tavily Web Search\n",
    "Searches the web for current, up-to-date information when the local knowledge base doesn't have the answer.\n",
    "\n",
    "### LangChain v1 Tool Pattern:\n",
    "In the new API, we use the `@tool` decorator to create tools with clear names and descriptions that help the agent decide when to use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Retriever tool created using @tool decorator\n"
     ]
    }
   ],
   "source": [
    "# Create retriever from vector store\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3}  # Retrieve top 3 most similar documents\n",
    ")\n",
    "\n",
    "# Create retriever tool using @tool decorator (NEW in LangChain v1)\n",
    "@tool\n",
    "def knowledge_base_search(query: str) -> str:\n",
    "    \"\"\"Search through the local knowledge base containing information about LangChain, \n",
    "    RAG (Retrieval-Augmented Generation), vector databases, AI agents, and GPT models. \n",
    "    Use this tool when the question is about fundamental AI/ML concepts, LangChain framework, \n",
    "    or technical explanations that don't require real-time information.\"\"\"\n",
    "    \n",
    "    docs = retriever.invoke(query)\n",
    "    # Format the retrieved documents\n",
    "    return \"\\n\\n\".join([f\"Document {i+1}:\\n{doc.page_content}\" for i, doc in enumerate(docs)])\n",
    "\n",
    "print(\"âœ… Retriever tool created using @tool decorator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Web search tool created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vineet\\AppData\\Local\\Temp\\ipykernel_8564\\2167215660.py:2: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the `langchain-tavily package and should be used instead. To use it run `pip install -U `langchain-tavily` and import as `from `langchain_tavily import TavilySearch``.\n",
      "  web_search_tool = TavilySearchResults(\n"
     ]
    }
   ],
   "source": [
    "# Create Tavily web search tool\n",
    "web_search_tool = TavilySearchResults(\n",
    "    max_results=3,\n",
    "    search_depth=\"advanced\",\n",
    "    include_answer=True,\n",
    "    include_raw_content=False,\n",
    "    include_images=False\n",
    ")\n",
    "\n",
    "print(\"âœ… Web search tool created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a calculator tool for addition\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two numbers together. Use this when you need to calculate the sum of two numbers.\n",
    "    Example: add(5, 3) returns 8\"\"\"\n",
    "    return a + b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a calculator tool for subtraction\n",
    "\n",
    "@tool\n",
    "def subtract(a: int, b: int) -> int:\n",
    "    \"\"\"Subtract b from a. Use this when you need to find the difference.\n",
    "    Example: subtract(10, 3) returns 7\"\"\"\n",
    "    return a - b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a calculator tool for multiplication\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers. Use this when you need to find the product.\n",
    "    Example: multiply(4, 5) returns 20\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ› ï¸  Available Tools for Agent:\n",
      "  1. knowledge_base_search: Search through the local knowledge base containing information about LangChain, \n",
      "    RAG (Retrieval-...\n",
      "  2. tavily_search_results_json: A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need...\n",
      "  3. add: Add two numbers together. Use this when you need to calculate the sum of two numbers.\n",
      "    Example: a...\n",
      "  4. subtract: Subtract b from a. Use this when you need to find the difference.\n",
      "    Example: subtract(10, 3) retur...\n",
      "  5. multiply: Multiply two numbers. Use this when you need to find the product.\n",
      "    Example: multiply(4, 5) return...\n"
     ]
    }
   ],
   "source": [
    "# Combine tools into a list\n",
    "tools = [knowledge_base_search, web_search_tool,add,subtract,multiply]\n",
    "\n",
    "print(\"\\nğŸ› ï¸  Available Tools for Agent:\")\n",
    "for i, tool in enumerate(tools, 1):\n",
    "    print(f\"  {i}. {tool.name}: {tool.description[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Initialize the Language Model\n",
    "\n",
    "We're using **GPT-4o** (GPT-4 Optimized) because:\n",
    "- Superior reasoning capabilities\n",
    "- Better function calling accuracy\n",
    "- Improved multi-step planning\n",
    "- Lower latency than GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Language model initialized: GPT-4o\n"
     ]
    }
   ],
   "source": [
    "# Initialize GPT-4o\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0,  # Set to 0 for consistent, deterministic outputs\n",
    "    streaming=True   # Enable streaming for better UX\n",
    ")\n",
    "\n",
    "print(\"âœ… Language model initialized: GPT-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create Agent with System Prompt\n",
    "\n",
    "### NEW LangChain v1 API - Simpler and More Powerful!\n",
    "\n",
    "Instead of creating separate prompt templates and agent executors, we now use:\n",
    "- **`create_agent()`** - Single function to create the agent\n",
    "- **`system_prompt`** - Direct string for instructions (no template needed)\n",
    "- Built on **LangGraph** - Automatic persistence, streaming, and human-in-the-loop\n",
    "\n",
    "The agent will:\n",
    "1. **Think** about which tool to use\n",
    "2. **Execute** the appropriate tool\n",
    "3. **Observe** the results\n",
    "4. **Iterate** if needed\n",
    "5. **Synthesize** a final answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… System prompt defined with current date: December 16, 2025\n"
     ]
    }
   ],
   "source": [
    "# Define system prompt for the agent with CURRENT DATE\n",
    "from datetime import datetime\n",
    "\n",
    "# Get current date to provide temporal context to the agent\n",
    "current_date = datetime.now().strftime(\"%B %d, %Y\")\n",
    "\n",
    "system_prompt = f\"\"\"You are a helpful AI assistant with access to multiple tools. \n",
    "Your goal is to answer user questions by reasoning about which tool to use.\n",
    "\n",
    "IMPORTANT: Today's date is {current_date}. Use this when searching for current information.\n",
    "\n",
    "REASONING PROCESS:\n",
    "1. Analyze the user's question carefully\n",
    "2. Determine if you need information from the knowledge base or the web\n",
    "3. Explain your reasoning before using a tool\n",
    "4. Use tools to gather information\n",
    "5. Synthesize the information into a clear, comprehensive answer\n",
    "\n",
    "You can:\n",
    "- Search a knowledge base about AI/ML concepts\n",
    "- Search the web for current information  \n",
    "- Perform mathematical calculations\n",
    "- Query structured databases\n",
    "\n",
    "Use your judgment to select appropriate tools based on the user's needs.\n",
    "\n",
    "Always explain your thought process clearly.\"\"\"\n",
    "\n",
    "print(f\"âœ… System prompt defined with current date: {current_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ”‘ Important: Providing Current Date Context\n",
    "\n",
    "**Problem**: LLMs are trained on historical data and don't inherently know \"today's date\"\n",
    "\n",
    "**Solution**: Inject the current date into the system prompt\n",
    "\n",
    "**Why This Matters**:\n",
    "- Without date context, the agent might use its training cutoff date\n",
    "- Critical for queries about \"today\", \"current\", \"latest\", \"now\"\n",
    "- Examples: weather, news, stock prices, events\n",
    "\n",
    "**Best Practice**: Always provide temporal context for production systems!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create the Agent Using LangChain v1 API\n",
    "\n",
    "### NEW: One-Line Agent Creation!\n",
    "\n",
    "The new `create_agent()` function replaces the old multi-step process:\n",
    "\n",
    "**Old Way (Deprecated):**\n",
    "```python\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "```\n",
    "\n",
    "**New Way (LangChain v1):**\n",
    "```python\n",
    "agent = create_agent(model=\"gpt-4o\", tools=tools, system_prompt=prompt)\n",
    "```\n",
    "\n",
    "### Benefits:\n",
    "âœ… Simpler API - one function instead of two\n",
    "âœ… Built on LangGraph - automatic persistence and streaming\n",
    "âœ… Better error handling\n",
    "âœ… Human-in-the-loop capabilities built-in\n",
    "âœ… Easier customization through middleware"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: See the Difference\n",
    "\n",
    "**Before (without date):**\n",
    "```\n",
    "Agent searches: \"London weather October 20, 2023\"  âŒ Wrong date!\n",
    "```\n",
    "\n",
    "**After (with date in prompt):**\n",
    "```\n",
    "Agent searches: \"London weather December 12, 2025\"  âœ… Correct date!\n",
    "```\n",
    "\n",
    "The agent now automatically includes the correct current date in time-sensitive queries!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agentic RAG system created with LangChain v1 API!\n",
      "\n",
      "ğŸ¤– Agent capabilities:\n",
      "   - Reason about tool selection\n",
      "   - Search local knowledge base\n",
      "   - Search the web for current information\n",
      "   - Combine multiple sources\n",
      "   - Built on LangGraph for reliability\n",
      "   - Automatic streaming and persistence\n",
      "\n",
      "ğŸ“ Note: The agent returns a graph that can be invoked with messages\n"
     ]
    }
   ],
   "source": [
    "# Create the agent using the new LangChain v1 API\n",
    "agent = create_agent(\n",
    "    model=llm_with_tools,              # Can also use string like \"gpt-4o\"\n",
    "    tools=tools,            # List of tools\n",
    "    system_prompt=system_prompt,  # Simple string prompt\n",
    ")\n",
    "\n",
    "print(\"âœ… Agentic RAG system created with LangChain v1 API!\")\n",
    "print(\"\\nğŸ¤– Agent capabilities:\")\n",
    "print(\"   - Reason about tool selection\")\n",
    "print(\"   - Search local knowledge base\")\n",
    "print(\"   - Search the web for current information\")\n",
    "print(\"   - Combine multiple sources\")\n",
    "print(\"   - Built on LangGraph for reliability\")\n",
    "print(\"   - Automatic streaming and persistence\")\n",
    "print(\"\\nğŸ“ Note: The agent returns a graph that can be invoked with messages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Test the Agent - Example Queries\n",
    "\n",
    "Let's test different scenarios to see how the agent reasons and decides which tool to use.\n",
    "\n",
    "### Understanding the Agent Reasoning Loop:\n",
    "\n",
    "The agent follows the **ReAct (Reasoning + Acting) pattern**:\n",
    "\n",
    "```\n",
    "1. ğŸ’­ THOUGHT: Agent analyzes the query and decides which tool to use\n",
    "2. ğŸ”§ ACTION: Agent calls the selected tool with appropriate input\n",
    "3. ğŸ‘ï¸  OBSERVATION: Agent receives and processes the tool's output\n",
    "4. ğŸ”„ REPEAT: If needed, agent can use more tools\n",
    "5. âœ… ANSWER: Agent synthesizes all information into final response\n",
    "```\n",
    "\n",
    "We'll visualize this loop for each query below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Helper function created! Use visualize_agent_reasoning(query) to see the complete reasoning loop.\n"
     ]
    }
   ],
   "source": [
    "# Helper function to visualize agent reasoning loop\n",
    "def visualize_agent_reasoning(query: str):\n",
    "    \"\"\"\n",
    "    Visualizes the complete reasoning loop of the agent showing:\n",
    "    - Which tools are selected\n",
    "    - What input is passed to each tool\n",
    "    - What observations the agent receives\n",
    "    - How the agent synthesizes the final answer\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ğŸ” QUERY: {query}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    print(\"ğŸ¤– AGENT REASONING LOOP (ReAct Pattern):\\n\")\n",
    "    \n",
    "    step_count = 0\n",
    "    tool_calls_count = 0\n",
    "    \n",
    "    for event in agent.stream(\n",
    "        {\"messages\": [HumanMessage(content=query)]},\n",
    "        stream_mode=\"values\"\n",
    "    ):\n",
    "        messages = event.get(\"messages\", [])\n",
    "        if messages:\n",
    "            last_msg = messages[-1]\n",
    "            \n",
    "            # Agent decides to use a tool (THOUGHT + ACTION)\n",
    "            if hasattr(last_msg, 'tool_calls') and last_msg.tool_calls:\n",
    "                step_count += 1\n",
    "                print(f\"{'â”'*80}\")\n",
    "                print(f\"ğŸ“ STEP {step_count}: THOUGHT + ACTION\")\n",
    "                print(f\"{'â”'*80}\")\n",
    "                print(f\"ğŸ’­ AGENT THINKING: Let me analyze this query and decide which tool to use...\\n\")\n",
    "                \n",
    "                for tool_call in last_msg.tool_calls:\n",
    "                    tool_calls_count += 1\n",
    "                    print(f\"ğŸ¯ DECISION: I will use '{tool_call['name']}' tool\")\n",
    "                    print(f\"ğŸ“‹ REASON: \", end=\"\")\n",
    "                    \n",
    "                    # Provide reasoning based on tool selected\n",
    "                    if \"knowledge_base\" in tool_call['name']:\n",
    "                        print(\"This query is about concepts in my knowledge base\")\n",
    "                    elif \"tavily\" in tool_call['name']:\n",
    "                        print(\"This requires current/real-time information from the web\")\n",
    "                    else:\n",
    "                        print(\"This tool will help me gather the needed information\")\n",
    "                    \n",
    "                    print(f\"\\nğŸ”§ TOOL: {tool_call['name']}\")\n",
    "                    print(f\"ğŸ“¥ INPUT: {tool_call['args']}\")\n",
    "                    print()\n",
    "            \n",
    "            # Agent receives tool output (OBSERVATION)\n",
    "            elif type(last_msg).__name__ == 'ToolMessage':\n",
    "                print(f\"{'â”'*80}\")\n",
    "                print(f\"ğŸ“ STEP {step_count}: OBSERVATION\")\n",
    "                print(f\"{'â”'*80}\")\n",
    "                print(f\"ğŸ‘ï¸  AGENT OBSERVING: Here's what the tool returned...\\n\")\n",
    "                \n",
    "                # Show truncated output\n",
    "                output = str(last_msg.content)\n",
    "                if len(output) > 400:\n",
    "                    print(f\"ğŸ“¤ TOOL OUTPUT (truncated):\\n{output[:400]}...\\n\")\n",
    "                else:\n",
    "                    print(f\"ğŸ“¤ TOOL OUTPUT:\\n{output}\\n\")\n",
    "                \n",
    "                print(f\"ğŸ’­ AGENT THINKING: Let me process this information...\")\n",
    "                print(f\"   â†’ Do I have enough information to answer?\")\n",
    "                print(f\"   â†’ Or do I need to use another tool?\\n\")\n",
    "    \n",
    "    # Get final result\n",
    "    result = agent.invoke({\"messages\": [HumanMessage(content=query)]})\n",
    "    \n",
    "    print(f\"{'â”'*80}\")\n",
    "    print(f\"ğŸ“ FINAL STEP: SYNTHESIS\")\n",
    "    print(f\"{'â”'*80}\")\n",
    "    print(f\"âœ… AGENT CONCLUSION: I have gathered sufficient information!\\n\")\n",
    "    print(f\"ğŸ“Š SUMMARY:\")\n",
    "    print(f\"   â€¢ Total tools used: {tool_calls_count}\")\n",
    "    print(f\"   â€¢ Reasoning steps: {step_count}\")\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ğŸ’¬ FINAL ANSWER:\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(result['messages'][-1].content)\n",
    "    print(f\"\\n{'='*80}\\n\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"âœ… Helper function created! Use visualize_agent_reasoning(query) to see the complete reasoning loop.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1: Question Requiring Local Knowledge Base\n",
    "\n",
    "**Expected Behavior:** Agent should use the `knowledge_base_search` tool since this information is in our vector database.\n",
    "\n",
    "**New Invocation Pattern:** The agent expects messages in a dict format with a \"messages\" key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ” QUERY: What is LangChain and what are its main components?\n",
      "================================================================================\n",
      "\n",
      "ğŸ¤– AGENT REASONING LOOP (ReAct Pattern):\n",
      "\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ“ STEP 1: THOUGHT + ACTION\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ’­ AGENT THINKING: Let me analyze this query and decide which tool to use...\n",
      "\n",
      "ğŸ¯ DECISION: I will use 'knowledge_base_search' tool\n",
      "ğŸ“‹ REASON: This query is about concepts in my knowledge base\n",
      "\n",
      "ğŸ”§ TOOL: knowledge_base_search\n",
      "ğŸ“¥ INPUT: {'query': 'LangChain main components'}\n",
      "\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ“ STEP 1: OBSERVATION\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ‘ï¸  AGENT OBSERVING: Here's what the tool returned...\n",
      "\n",
      "ğŸ“¤ TOOL OUTPUT (truncated):\n",
      "Document 1:\n",
      "LangChain is a framework for developing applications powered by language models. \n",
      "        It enables applications that are context-aware and can reason. LangChain provides standard, \n",
      "        extendable interfaces and integrations for various components like model I/O, retrieval, \n",
      "        agents, and memory. The framework was created by Harrison Chase and launched in October 2022.\n",
      "\n",
      "Docu...\n",
      "\n",
      "ğŸ’­ AGENT THINKING: Let me process this information...\n",
      "   â†’ Do I have enough information to answer?\n",
      "   â†’ Or do I need to use another tool?\n",
      "\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ“ FINAL STEP: SYNTHESIS\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "âœ… AGENT CONCLUSION: I have gathered sufficient information!\n",
      "\n",
      "ğŸ“Š SUMMARY:\n",
      "   â€¢ Total tools used: 1\n",
      "   â€¢ Reasoning steps: 1\n",
      "\n",
      "================================================================================\n",
      "ğŸ’¬ FINAL ANSWER:\n",
      "================================================================================\n",
      "LangChain is a framework designed for developing applications that are powered by language models. It allows for the creation of applications that are context-aware and capable of reasoning. The framework provides standard, extendable interfaces and integrations for several key components, which include:\n",
      "\n",
      "1. **Model I/O**: Interfaces for input and output operations with language models.\n",
      "2. **Retrieval**: Mechanisms to fetch and utilize external data sources.\n",
      "3. **Agents**: Components that can make decisions and perform actions based on the language model's outputs.\n",
      "4. **Memory**: Systems to store and recall information, enabling the application to maintain context over interactions.\n",
      "\n",
      "LangChain was created by Harrison Chase and was launched in October 2022.\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "query1 = \"What is LangChain and what are its main components?\"\n",
    "\n",
    "# Use the helper function to visualize reasoning\n",
    "result1 = visualize_agent_reasoning(query1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2: Question Requiring Web Search\n",
    "\n",
    "**Expected Behavior:** Agent should use the `tavily_search_results_json` tool since this requires current information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ” QUERY: What are the latest updates in GPT-4 in 2025?\n",
      "================================================================================\n",
      "\n",
      "ğŸ¤– AGENT REASONING LOOP (ReAct Pattern):\n",
      "\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ“ STEP 1: THOUGHT + ACTION\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ’­ AGENT THINKING: Let me analyze this query and decide which tool to use...\n",
      "\n",
      "ğŸ¯ DECISION: I will use 'tavily_search_results_json' tool\n",
      "ğŸ“‹ REASON: This requires current/real-time information from the web\n",
      "\n",
      "ğŸ”§ TOOL: tavily_search_results_json\n",
      "ğŸ“¥ INPUT: {'query': 'latest updates in GPT-4 2025'}\n",
      "\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ“ STEP 1: OBSERVATION\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ‘ï¸  AGENT OBSERVING: Here's what the tool returned...\n",
      "\n",
      "ğŸ“¤ TOOL OUTPUT (truncated):\n",
      "[{\"title\": \"ChatGPT â€” Release Notes: 2025-March-27 - GPT-4o a new update\", \"url\": \"https://community.openai.com/t/chatgpt-release-notes-2025-march-27-gpt-4o-a-new-update/1153887\", \"content\": \"# ChatGPT â€” Release Notes: 2025-March-27 - GPT-4o a new update\\n\\nOpenAI just gave GPT-4o a new update. Based on content on OpenAI help page:\\n\\nThis model is now available in ChatGPT and in the API as the ne...\n",
      "\n",
      "ğŸ’­ AGENT THINKING: Let me process this information...\n",
      "   â†’ Do I have enough information to answer?\n",
      "   â†’ Or do I need to use another tool?\n",
      "\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ“ FINAL STEP: SYNTHESIS\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "âœ… AGENT CONCLUSION: I have gathered sufficient information!\n",
      "\n",
      "ğŸ“Š SUMMARY:\n",
      "   â€¢ Total tools used: 1\n",
      "   â€¢ Reasoning steps: 1\n",
      "\n",
      "================================================================================\n",
      "ğŸ’¬ FINAL ANSWER:\n",
      "================================================================================\n",
      "The latest updates in GPT-4 for 2025 include the introduction of GPT-4o, which is an enhanced version of GPT-4. Here are some key updates and features:\n",
      "\n",
      "1. **Improved Performance**: GPT-4o offers faster responses compared to the original GPT-4. It also shows significant improvements in benchmark results, such as MMLU, GPQA, MATH, and HumanEval scores.\n",
      "\n",
      "2. **Multimodal Capabilities**: While GPT-4 had limited multimodal support, GPT-4o extends this capability significantly. It can handle inputs in text, audio, image, and video formats, and produce outputs in text, audio, and image formats.\n",
      "\n",
      "3. **Enhanced Creativity and Collaboration**: GPT-4o is designed to be more intuitive, creative, and collaborative, following instructions more accurately and handling coding tasks more smoothly.\n",
      "\n",
      "4. **Retirement of GPT-4**: With the advancements in GPT-4o and other models, GPT-4 has been retired. OpenAI has also released other models like GPT-4.5 and mini versions like o3 and o4, further emphasizing the transition from GPT-4.\n",
      "\n",
      "These updates reflect OpenAI's ongoing efforts to enhance the capabilities and performance of their AI models.\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query2 = \"What are the latest updates in GPT-4 in 2025?\"\n",
    "\n",
    "# Use the helper function to visualize reasoning\n",
    "result2 = visualize_agent_reasoning(query2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ” QUERY: Tell me something about google antigravity?\n",
      "================================================================================\n",
      "\n",
      "ğŸ¤– AGENT REASONING LOOP (ReAct Pattern):\n",
      "\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ“ STEP 1: THOUGHT + ACTION\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ’­ AGENT THINKING: Let me analyze this query and decide which tool to use...\n",
      "\n",
      "ğŸ¯ DECISION: I will use 'tavily_search_results_json' tool\n",
      "ğŸ“‹ REASON: This requires current/real-time information from the web\n",
      "\n",
      "ğŸ”§ TOOL: tavily_search_results_json\n",
      "ğŸ“¥ INPUT: {'query': 'Google antigravity December 15, 2025'}\n",
      "\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ“ STEP 1: OBSERVATION\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ‘ï¸  AGENT OBSERVING: Here's what the tool returned...\n",
      "\n",
      "ğŸ“¤ TOOL OUTPUT (truncated):\n",
      "[{\"title\": \"Google Antigravity - Wikipedia\", \"url\": \"https://en.wikipedia.org/wiki/Google_Antigravity\", \"content\": \"Google Antigravity is an AI-powered integrated development environment (IDE) developed by Google, designed for prioritizing AI agents platform for software development. Announced on November 18, 2025 alongside the release of Gemini \\\"Gemini (language model)\\\") 3, Antigravity enables ...\n",
      "\n",
      "ğŸ’­ AGENT THINKING: Let me process this information...\n",
      "   â†’ Do I have enough information to answer?\n",
      "   â†’ Or do I need to use another tool?\n",
      "\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ“ FINAL STEP: SYNTHESIS\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "âœ… AGENT CONCLUSION: I have gathered sufficient information!\n",
      "\n",
      "ğŸ“Š SUMMARY:\n",
      "   â€¢ Total tools used: 1\n",
      "   â€¢ Reasoning steps: 1\n",
      "\n",
      "================================================================================\n",
      "ğŸ’¬ FINAL ANSWER:\n",
      "================================================================================\n",
      "Google Antigravity is an AI-powered integrated development environment (IDE) developed by Google, designed to prioritize AI agents for software development. It was announced on November 18, 2025, alongside the release of Google's Gemini 3 AI model. Antigravity enables developers to delegate complex coding tasks to autonomous AI agents powered primarily by the Gemini 3 Pro model. The platform is built as a fork of Visual Studio Code and is available on 64-bit Windows, macOS, and Linux systems.\n",
      "\n",
      "Antigravity represents an evolution of the IDE into an agent-first future, with capabilities like browser control and asynchronous interaction patterns. It is currently in a public preview phase, with the latest preview release being on December 8, 2025. The platform is proprietary but free during the preview period.\n",
      "\n",
      "For more detailed information, you can visit the [Google Antigravity Wikipedia page](https://en.wikipedia.org/wiki/Google_Antigravity) or check out the [official website](https://antigravity.google).\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query2 = \"Tell me something about google antigravity?\"\n",
    "\n",
    "# Use the helper function to visualize reasoning\n",
    "result2 = visualize_agent_reasoning(query2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3: Question Potentially Requiring Both Tools\n",
    "\n",
    "**Expected Behavior:** Agent might use both tools to combine local knowledge with current information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ” QUERY: How does RAG work and what are some recent improvements to RAG systems?\n",
      "================================================================================\n",
      "\n",
      "ğŸ¤– AGENT REASONING LOOP (ReAct Pattern):\n",
      "\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ“ STEP 1: THOUGHT + ACTION\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ’­ AGENT THINKING: Let me analyze this query and decide which tool to use...\n",
      "\n",
      "ğŸ¯ DECISION: I will use 'knowledge_base_search' tool\n",
      "ğŸ“‹ REASON: This query is about concepts in my knowledge base\n",
      "\n",
      "ğŸ”§ TOOL: knowledge_base_search\n",
      "ğŸ“¥ INPUT: {'query': 'How does Retrieval-Augmented Generation (RAG) work?'}\n",
      "\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ“ STEP 1: OBSERVATION\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ‘ï¸  AGENT OBSERVING: Here's what the tool returned...\n",
      "\n",
      "ğŸ“¤ TOOL OUTPUT (truncated):\n",
      "Document 1:\n",
      "Retrieval-Augmented Generation (RAG) is a technique that combines the power of \n",
      "        large language models with external knowledge retrieval. It works by first retrieving relevant \n",
      "        documents from a knowledge base, then using those documents as context for the LLM to generate \n",
      "        an answer. This approach reduces hallucinations and provides more accurate, grounded respons...\n",
      "\n",
      "ğŸ’­ AGENT THINKING: Let me process this information...\n",
      "   â†’ Do I have enough information to answer?\n",
      "   â†’ Or do I need to use another tool?\n",
      "\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ“ STEP 2: THOUGHT + ACTION\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ’­ AGENT THINKING: Let me analyze this query and decide which tool to use...\n",
      "\n",
      "ğŸ¯ DECISION: I will use 'tavily_search_results_json' tool\n",
      "ğŸ“‹ REASON: This requires current/real-time information from the web\n",
      "\n",
      "ğŸ”§ TOOL: tavily_search_results_json\n",
      "ğŸ“¥ INPUT: {'query': 'recent improvements in Retrieval-Augmented Generation systems 2025'}\n",
      "\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ“ STEP 2: OBSERVATION\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ‘ï¸  AGENT OBSERVING: Here's what the tool returned...\n",
      "\n",
      "ğŸ“¤ TOOL OUTPUT (truncated):\n",
      "[{\"title\": \"Advancements in RAG [Retrieval-Augmented Generation] Systems ...\", \"url\": \"https://medium.com/@martinagrafsvw25/advancements-in-rag-retrieval-augmented-generation-systems-by-mid-2025-935a39c15ae9\", \"content\": \"As of mid-2025, Retrieval-Augmented Generation (RAG) continues to be a foundational architecture for enhancing Large Language Models with\", \"score\": 0.99974877}, {\"title\": \"RAG i...\n",
      "\n",
      "ğŸ’­ AGENT THINKING: Let me process this information...\n",
      "   â†’ Do I have enough information to answer?\n",
      "   â†’ Or do I need to use another tool?\n",
      "\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ“ FINAL STEP: SYNTHESIS\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "âœ… AGENT CONCLUSION: I have gathered sufficient information!\n",
      "\n",
      "ğŸ“Š SUMMARY:\n",
      "   â€¢ Total tools used: 2\n",
      "   â€¢ Reasoning steps: 2\n",
      "\n",
      "================================================================================\n",
      "ğŸ’¬ FINAL ANSWER:\n",
      "================================================================================\n",
      "Recent improvements in Retrieval-Augmented Generation (RAG) systems include several key advancements:\n",
      "\n",
      "1. **Sufficient Context**: A recent study presented at ICLR 2025 introduced the concept of \"sufficient context\" in RAG systems. This research focuses on determining when a language model has enough information to provide a correct answer. By quantifying context sufficiency, the study aims to reduce hallucinations by ensuring that the model has adequate context before generating responses. Recommendations from this research include adding a sufficiency check before generation, retrieving more context, re-ranking retrieved contexts, and tuning an abstention threshold based on confidence and context signals. [Read more](https://research.google/blog/deeper-insights-into-retrieval-augmented-generation-the-role-of-sufficient-context/)\n",
      "\n",
      "2. **RAG as a Foundational Capability**: Predictions for 2026 suggest that RAG will transition from an experimental innovation to a foundational capability in AI systems. RAG platforms are expected to evolve into full-featured environments with modular capabilities, enhancing productivity by integrating verified organizational data into generative responses. This shift will blur the lines between traditional SaaS and emerging AI-as-a-Service models, making RAG an essential layer for business operations. [Read more](https://vmblog.com/archive/2025/12/15/retrieval-augmented-generation-rag-redefining-the-ai-landscape-in-2026.aspx)\n",
      "\n",
      "3. **RAG-R for National Security**: A development known as RAG-R focuses on using RAG systems for national security by integrating real-time access to authoritative, mission-specific data. This approach allows generative models to focus on reasoning and operational decision-making, addressing core limitations in national security environments. [Read more](https://www.executivebiz.com/articles/saic-jay-meil-rag-r-llm-national-security)\n",
      "\n",
      "These advancements highlight the ongoing evolution of RAG systems, emphasizing improvements in context management, integration into business processes, and specialized applications in security.\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query3 = \"How does RAG work and what are some recent improvements to RAG systems?\"\n",
    "\n",
    "# This query might trigger MULTIPLE tool calls - watch the reasoning loop!\n",
    "result3 = visualize_agent_reasoning(query3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ” QUERY: What is 10-5?\n",
      "================================================================================\n",
      "\n",
      "ğŸ¤– AGENT REASONING LOOP (ReAct Pattern):\n",
      "\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ“ STEP 1: THOUGHT + ACTION\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ’­ AGENT THINKING: Let me analyze this query and decide which tool to use...\n",
      "\n",
      "ğŸ¯ DECISION: I will use 'subtract' tool\n",
      "ğŸ“‹ REASON: This tool will help me gather the needed information\n",
      "\n",
      "ğŸ”§ TOOL: subtract\n",
      "ğŸ“¥ INPUT: {'a': 10, 'b': 5}\n",
      "\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ“ STEP 1: OBSERVATION\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ‘ï¸  AGENT OBSERVING: Here's what the tool returned...\n",
      "\n",
      "ğŸ“¤ TOOL OUTPUT:\n",
      "5\n",
      "\n",
      "ğŸ’­ AGENT THINKING: Let me process this information...\n",
      "   â†’ Do I have enough information to answer?\n",
      "   â†’ Or do I need to use another tool?\n",
      "\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ“ FINAL STEP: SYNTHESIS\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "âœ… AGENT CONCLUSION: I have gathered sufficient information!\n",
      "\n",
      "ğŸ“Š SUMMARY:\n",
      "   â€¢ Total tools used: 1\n",
      "   â€¢ Reasoning steps: 1\n",
      "\n",
      "================================================================================\n",
      "ğŸ’¬ FINAL ANSWER:\n",
      "================================================================================\n",
      "The result of 10 minus 5 is 5.\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query3 = \"What is 10-5?\"\n",
    "\n",
    "# This query might trigger MULTIPLE tool calls - watch the reasoning loop!\n",
    "result3 = visualize_agent_reasoning(query3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ” QUERY: What is 30 multiply by 30 minus 200?What are the recent research paper in mathematics\n",
      "================================================================================\n",
      "\n",
      "ğŸ¤– AGENT REASONING LOOP (ReAct Pattern):\n",
      "\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ“ STEP 1: THOUGHT + ACTION\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ’­ AGENT THINKING: Let me analyze this query and decide which tool to use...\n",
      "\n",
      "ğŸ¯ DECISION: I will use 'multiply' tool\n",
      "ğŸ“‹ REASON: This tool will help me gather the needed information\n",
      "\n",
      "ğŸ”§ TOOL: multiply\n",
      "ğŸ“¥ INPUT: {'a': 30, 'b': 30}\n",
      "\n",
      "ğŸ¯ DECISION: I will use 'tavily_search_results_json' tool\n",
      "ğŸ“‹ REASON: This requires current/real-time information from the web\n",
      "\n",
      "ğŸ”§ TOOL: tavily_search_results_json\n",
      "ğŸ“¥ INPUT: {'query': 'recent research papers in mathematics 2025'}\n",
      "\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ“ STEP 1: OBSERVATION\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ‘ï¸  AGENT OBSERVING: Here's what the tool returned...\n",
      "\n",
      "ğŸ“¤ TOOL OUTPUT (truncated):\n",
      "[{\"title\": \"Dr. R. Tharaniya sairaj\", \"url\": \"https://orkg.org/u/40c34255-9d25-41d2-9357-d76d2c5e9fba?page=0\", \"content\": \"... mathematics mindset and mathematics anxiety. Paper. Science. Semiha Kula ... This dataset presents a comparative overview of five recent research papers (2025) ...Read more\", \"score\": 0.8138313}, {\"title\": \"Mathematics - Simple English Wikipedia, the free encyclopedia\", \"u...\n",
      "\n",
      "ğŸ’­ AGENT THINKING: Let me process this information...\n",
      "   â†’ Do I have enough information to answer?\n",
      "   â†’ Or do I need to use another tool?\n",
      "\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ“ STEP 2: THOUGHT + ACTION\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ’­ AGENT THINKING: Let me analyze this query and decide which tool to use...\n",
      "\n",
      "ğŸ¯ DECISION: I will use 'subtract' tool\n",
      "ğŸ“‹ REASON: This tool will help me gather the needed information\n",
      "\n",
      "ğŸ”§ TOOL: subtract\n",
      "ğŸ“¥ INPUT: {'a': 900, 'b': 200}\n",
      "\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ“ STEP 2: OBSERVATION\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ‘ï¸  AGENT OBSERVING: Here's what the tool returned...\n",
      "\n",
      "ğŸ“¤ TOOL OUTPUT:\n",
      "700\n",
      "\n",
      "ğŸ’­ AGENT THINKING: Let me process this information...\n",
      "   â†’ Do I have enough information to answer?\n",
      "   â†’ Or do I need to use another tool?\n",
      "\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ“ FINAL STEP: SYNTHESIS\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "âœ… AGENT CONCLUSION: I have gathered sufficient information!\n",
      "\n",
      "ğŸ“Š SUMMARY:\n",
      "   â€¢ Total tools used: 3\n",
      "   â€¢ Reasoning steps: 2\n",
      "\n",
      "================================================================================\n",
      "ğŸ’¬ FINAL ANSWER:\n",
      "================================================================================\n",
      "The result of \\(30 \\times 30 - 200\\) is 700.\n",
      "\n",
      "Regarding recent research papers in mathematics, here are some notable publications:\n",
      "\n",
      "1. **Research in Mathematics: Vol 12, No 1 (Current issue)** - This is the current issue of the journal \"Research in Mathematics,\" which you can explore for the latest articles. [Read more here](https://www.tandfonline.com/toc/oama23/current).\n",
      "\n",
      "2. **Quantum many-body physics calculations with large ...** - A recent paper by H. Pan, published in 2025, discusses advancements in quantum many-body physics calculations, which involve complex mathematical models and numerical solutions. [Read more here](https://www.nature.com/articles/s42005-025-01956-y).\n",
      "\n",
      "These resources should provide you with insights into the latest developments in the field of mathematics.\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query3 = \"What is 30 multiply by 30 minus 200?What are the recent research paper in mathematics\"\n",
    "\n",
    "# This query might trigger MULTIPLE tool calls - watch the reasoning loop!\n",
    "result3 = visualize_agent_reasoning(query3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ” QUERY: How is the weather in Delhi today?\n",
      "================================================================================\n",
      "\n",
      "ğŸ¤– AGENT REASONING LOOP (ReAct Pattern):\n",
      "\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ“ STEP 1: THOUGHT + ACTION\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ’­ AGENT THINKING: Let me analyze this query and decide which tool to use...\n",
      "\n",
      "ğŸ¯ DECISION: I will use 'tavily_search_results_json' tool\n",
      "ğŸ“‹ REASON: This requires current/real-time information from the web\n",
      "\n",
      "ğŸ”§ TOOL: tavily_search_results_json\n",
      "ğŸ“¥ INPUT: {'query': 'Delhi weather December 16 2025'}\n",
      "\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ“ STEP 1: OBSERVATION\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ‘ï¸  AGENT OBSERVING: Here's what the tool returned...\n",
      "\n",
      "ğŸ“¤ TOOL OUTPUT (truncated):\n",
      "[{\"title\": \"Delhi weather in December 2025 - Weather25.com\", \"url\": \"https://www.weather25.com/asia/india/delhi?page=month&month=December\", \"content\": \"| 14 Image 41: Overcast 78Â°/64Â° | 15 Image 42: Sunny 80Â°/62Â° | 16 Image 43: Sunny 78Â°/62Â° | 17 Image 44: Sunny 78Â°/62Â° | 18 Image 45: Sunny 80Â°/62Â° | 19 Image 46: Sunny 80Â°/64Â° | 20 Image 47: Sunny 80Â°/64Â° |\\n| 21 Image 48: Sunny 80Â°/64Â° | 22 Image...\n",
      "\n",
      "ğŸ’­ AGENT THINKING: Let me process this information...\n",
      "   â†’ Do I have enough information to answer?\n",
      "   â†’ Or do I need to use another tool?\n",
      "\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ“ FINAL STEP: SYNTHESIS\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "âœ… AGENT CONCLUSION: I have gathered sufficient information!\n",
      "\n",
      "ğŸ“Š SUMMARY:\n",
      "   â€¢ Total tools used: 1\n",
      "   â€¢ Reasoning steps: 1\n",
      "\n",
      "================================================================================\n",
      "ğŸ’¬ FINAL ANSWER:\n",
      "================================================================================\n",
      "Today, December 16, 2025, the weather in Delhi is sunny with temperatures around 78Â°F (approximately 26Â°C) during the day and dropping to about 62Â°F (approximately 17Â°C) at night.\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query3 = \"How is the weather in Delhi today?\"\n",
    "\n",
    "# This query might trigger MULTIPLE tool calls - watch the reasoning loop!\n",
    "result3 = visualize_agent_reasoning(query3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 4: Complex Reasoning Question\n",
    "\n",
    "**Expected Behavior:** Agent should demonstrate multi-step reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query4 = \"Explain how LangChain agents work and compare them to traditional RAG approaches\"\n",
    "\n",
    "# Complex query requiring deep reasoning\n",
    "result4 = visualize_agent_reasoning(query4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Analyze Agent Reasoning and Messages\n",
    "\n",
    "Let's examine the message flow to understand how the agent reasoned through the queries.\n",
    "\n",
    "In LangChain v1, the agent returns all messages including:\n",
    "- **HumanMessage**: User input\n",
    "- **AIMessage**: Agent's reasoning and tool calls\n",
    "- **ToolMessage**: Results from tool execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 5: Multi-Tool Reasoning Example\n",
    "\n",
    "This query will likely require the agent to use **BOTH tools** - demonstrating advanced multi-step reasoning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query5 = \"What is RAG and how is it being used in AI applications today?\"\n",
    "\n",
    "print(\"âš¡ SPECIAL CASE: This query requires BOTH local knowledge AND current web information!\")\n",
    "print(\"Watch how the agent uses multiple tools in sequence!\\n\")\n",
    "\n",
    "# This should demonstrate multi-tool usage\n",
    "result5 = visualize_agent_reasoning(query5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display agent reasoning steps\n",
    "def analyze_agent_reasoning(result, query_name):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ğŸ§  REASONING ANALYSIS: {query_name}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    messages = result['messages']\n",
    "    print(f\"ğŸ“Š Total messages: {len(messages)}\\n\")\n",
    "    \n",
    "    for i, msg in enumerate(messages, 1):\n",
    "        print(f\"\\n--- Message {i}: {type(msg).__name__} ---\")\n",
    "        \n",
    "        if hasattr(msg, 'content') and msg.content:\n",
    "            print(f\"ğŸ’¬ Content: {msg.content[:200]}...\")\n",
    "        \n",
    "        # Check for tool calls in AIMessage\n",
    "        if hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
    "            for tool_call in msg.tool_calls:\n",
    "                print(f\"ğŸ”§ Tool Called: {tool_call['name']}\")\n",
    "                print(f\"ğŸ“¥ Tool Input: {tool_call['args']}\")\n",
    "        \n",
    "        # Check for tool results\n",
    "        if type(msg).__name__ == 'ToolMessage':\n",
    "            print(f\"ğŸ“¤ Tool Output: {str(msg.content)[:200]}...\")\n",
    "        \n",
    "        print(\"-\" * 80)\n",
    "\n",
    "# Analyze the reasoning for query 1\n",
    "analyze_agent_reasoning(result1, \"Query 1 - Local Knowledge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Understanding the Agent Reasoning Loop\n",
    "\n",
    "### What You Just Saw: The ReAct Pattern\n",
    "\n",
    "The agent follows a **ReAct (Reasoning + Acting)** loop for each query:\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    USER QUERY RECEIVED                       â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                  â”‚\n",
    "                  â–¼\n",
    "          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "          â”‚  ğŸ’­ THOUGHT   â”‚  Agent analyzes the query\n",
    "          â”‚  (Reasoning)  â”‚  \"What information do I need?\"\n",
    "          â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  \"Which tool should I use?\"\n",
    "                  â”‚\n",
    "                  â–¼\n",
    "          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "          â”‚  ğŸ”§ ACTION    â”‚  Agent selects and calls a tool\n",
    "          â”‚  (Tool Call)  â”‚  with appropriate input\n",
    "          â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                  â”‚\n",
    "                  â–¼\n",
    "          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "          â”‚ ğŸ‘ï¸ OBSERVATIONâ”‚  Agent receives tool output\n",
    "          â”‚  (Tool Result)â”‚  and processes the information\n",
    "          â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                  â”‚\n",
    "                  â–¼\n",
    "          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "          â”‚   ğŸ¤” EVALUATE â”‚  \"Do I have enough info?\"\n",
    "          â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                  â”‚\n",
    "         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "         â”‚                 â”‚\n",
    "    Need more info?   Have enough?\n",
    "         â”‚                 â”‚\n",
    "         â–¼                 â–¼\n",
    "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚ REPEAT  â”‚      â”‚ âœ… ANSWERâ”‚\n",
    "    â”‚  LOOP   â”‚      â”‚ (Synthesis)â”‚\n",
    "    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### Key Observations from Tests:\n",
    "\n",
    "1. **Tool Selection Intelligence**: \n",
    "   - Agent chose `knowledge_base_search` for conceptual questions\n",
    "   - Agent chose `tavily_search_results_json` for current events\n",
    "\n",
    "2. **Multi-Step Reasoning**: \n",
    "   - Some queries required multiple tool calls\n",
    "   - Agent evaluated each result before deciding next step\n",
    "\n",
    "3. **Context Synthesis**: \n",
    "   - Agent combined information from multiple sources\n",
    "   - Final answer was coherent and comprehensive\n",
    "\n",
    "4. **Transparency**:\n",
    "   - Every decision and tool call is visible\n",
    "   - You can see exactly how the agent \"thinks\"\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Deep Dive - Analyzing Message Flow\n",
    "\n",
    "Let's examine the complete message history to understand the agent's internal communication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ”¬ MESSAGE FLOW ANALYSIS: Query 1 - LangChain Components\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š Total messages in conversation: 4\n",
      "\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Message #1: HumanMessage\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ‘¤ USER INPUT:\n",
      "   What is LangChain and what are its main components?\n",
      "\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Message #2: AIMessage\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ¤– AGENT DECISION: Using tools\n",
      "\n",
      "   Tool Call #1:\n",
      "   â””â”€ Tool: knowledge_base_search\n",
      "   â””â”€ Arguments: {'query': 'LangChain main components'}\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Message #3: ToolMessage\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ”§ TOOL RESULT:\n",
      "   Document 1:\n",
      "LangChain is a framework for developing applications powered by language models. \n",
      "        It enables applications that are context-aware and can reason. LangChain provides standard, \n",
      "     ...\n",
      "   â””â”€ Tool used: knowledge_base_search\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Message #4: AIMessage\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ¤– AGENT FINAL RESPONSE:\n",
      "   LangChain is a framework designed for developing applications powered by language models. It enables the creation of applications that are context-aware and capable of reasoning. The framework provide...\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Detailed message analysis function\n",
    "def analyze_message_flow(result, query_name):\n",
    "    \"\"\"\n",
    "    Analyzes the complete message flow showing all message types:\n",
    "    - HumanMessage: User input\n",
    "    - AIMessage: Agent's decisions and reasoning\n",
    "    - ToolMessage: Tool execution results\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ğŸ”¬ MESSAGE FLOW ANALYSIS: {query_name}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    messages = result['messages']\n",
    "    print(f\"ğŸ“Š Total messages in conversation: {len(messages)}\\n\")\n",
    "    \n",
    "    for i, msg in enumerate(messages, 1):\n",
    "        msg_type = type(msg).__name__\n",
    "        print(f\"\\n{'â”€'*80}\")\n",
    "        print(f\"Message #{i}: {msg_type}\")\n",
    "        print(f\"{'â”€'*80}\")\n",
    "        \n",
    "        if msg_type == 'HumanMessage':\n",
    "            print(f\"ğŸ‘¤ USER INPUT:\")\n",
    "            print(f\"   {msg.content}\\n\")\n",
    "        \n",
    "        elif msg_type == 'AIMessage':\n",
    "            # Check if this is a tool-calling message or final response\n",
    "            if hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
    "                print(f\"ğŸ¤– AGENT DECISION: Using tools\")\n",
    "                for j, tool_call in enumerate(msg.tool_calls, 1):\n",
    "                    print(f\"\\n   Tool Call #{j}:\")\n",
    "                    print(f\"   â””â”€ Tool: {tool_call['name']}\")\n",
    "                    print(f\"   â””â”€ Arguments: {tool_call['args']}\")\n",
    "            else:\n",
    "                print(f\"ğŸ¤– AGENT FINAL RESPONSE:\")\n",
    "                content = msg.content[:200] if len(msg.content) > 200 else msg.content\n",
    "                print(f\"   {content}...\")\n",
    "        \n",
    "        elif msg_type == 'ToolMessage':\n",
    "            print(f\"ğŸ”§ TOOL RESULT:\")\n",
    "            content = str(msg.content)[:200] if len(str(msg.content)) > 200 else str(msg.content)\n",
    "            print(f\"   {content}...\")\n",
    "            if hasattr(msg, 'name'):\n",
    "                print(f\"   â””â”€ Tool used: {msg.name}\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\\n\")\n",
    "\n",
    "# Analyze one of our previous results\n",
    "analyze_message_flow(result1, \"Query 1 - LangChain Components\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Insights from Message Flow Analysis:\n",
    "\n",
    "1. **Message Types**:\n",
    "   - `HumanMessage`: Contains user query\n",
    "   - `AIMessage` (with tool_calls): Agent's decision to use tools\n",
    "   - `ToolMessage`: Results from tool execution\n",
    "   - `AIMessage` (without tool_calls): Final synthesized answer\n",
    "\n",
    "2. **Conversation Structure**:\n",
    "   ```\n",
    "   HumanMessage â†’ AIMessage (tool decision) â†’ ToolMessage â†’ AIMessage (final answer)\n",
    "   ```\n",
    "\n",
    "3. **Why This Matters**:\n",
    "   - **Transparency**: See every decision the agent makes\n",
    "   - **Debugging**: Identify where issues occur in the reasoning chain\n",
    "   - **Optimization**: Understand which tools are used most frequently\n",
    "   - **Auditing**: Track all tool calls for compliance/monitoring\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Bonus: Streaming Agent Responses in Real-Time\n",
    "\n",
    "One of the key benefits of LangChain v1 built on LangGraph is **native streaming support**.\n",
    "\n",
    "Watch the agent think and act in real-time!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming example with real-time reasoning visualization\n",
    "import time\n",
    "\n",
    "query_stream = \"What is vector database and why is it important for RAG?\"\n",
    "\n",
    "print(\"ğŸŒŠ STREAMING MODE: Watch the agent think in REAL-TIME!\\n\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"ğŸ” QUERY: {query_stream}\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "chunk_count = 0\n",
    "for chunk in agent.stream(\n",
    "    {\"messages\": [HumanMessage(content=query_stream)]},\n",
    "    stream_mode=\"values\"  # Stream complete state updates\n",
    "):\n",
    "    chunk_count += 1\n",
    "    messages = chunk.get(\"messages\", [])\n",
    "    \n",
    "    if messages:\n",
    "        last_msg = messages[-1]\n",
    "        msg_type = type(last_msg).__name__\n",
    "        \n",
    "        # Show different visualizations based on message type\n",
    "        if msg_type == \"AIMessage\" and hasattr(last_msg, 'tool_calls') and last_msg.tool_calls:\n",
    "            print(f\"âš¡ Chunk #{chunk_count}: Agent selecting tool...\")\n",
    "            for tool_call in last_msg.tool_calls:\n",
    "                print(f\"   ğŸ”§ {tool_call['name']}\")\n",
    "        \n",
    "        elif msg_type == \"ToolMessage\":\n",
    "            print(f\"âš¡ Chunk #{chunk_count}: Tool execution complete\")\n",
    "            print(f\"   ğŸ“¤ Result received ({len(str(last_msg.content))} chars)\")\n",
    "        \n",
    "        elif msg_type == \"AIMessage\" and last_msg.content:\n",
    "            print(f\"âš¡ Chunk #{chunk_count}: Generating final answer...\")\n",
    "    \n",
    "    print(f\"{'.'*40}\")\n",
    "\n",
    "print(f\"\\nâœ… Streaming complete! Total chunks: {chunk_count}\")\n",
    "print(f\"\\n{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Benefits:\n",
    "\n",
    "âœ… **Real-time feedback**: Users see progress immediately\n",
    "âœ… **Better UX**: No waiting for complete response\n",
    "âœ… **Debugging**: Watch the agent's reasoning unfold\n",
    "âœ… **Monitoring**: Track agent behavior live\n",
    "\n",
    "### Stream Modes Available:\n",
    "\n",
    "- `\"values\"`: Complete state at each step\n",
    "- `\"updates\"`: Only what changed since last step  \n",
    "- `\"messages\"`: Individual messages as they're created\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example setup using NEW create_agent API\n",
    "print(\"\"\"\n",
    "# NEW LangChain v1 approach with @tool decorator\n",
    "from langchain.tools import tool\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "\n",
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    '''Evaluate a mathematical expression and return the result.'''\n",
    "    try:\n",
    "        result = eval(expression, {\"__builtins__\": {}}, {})\n",
    "        return str(result)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "python_repl = PythonREPLTool()\n",
    "\n",
    "# Create agent with NEW API\n",
    "agent_with_calc = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[knowledge_base_search, calculator, python_repl],\n",
    "    system_prompt=\"You are a technical assistant that can search docs and perform calculations.\"\n",
    ")\n",
    "\n",
    "# Agent workflow:\n",
    "# 1. Retrieve information about GPT-3 training\n",
    "# 2. Use calculator for simple math (355 GPU-years * 365 days * 24 hours * $2)\n",
    "# 3. Use Python REPL for complex calculations\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: SQL Database + Retriever + Web Search\n",
    "\n",
    "**Use Case:** Answer questions about structured data with contextual information\n",
    "\n",
    "**Tools:**\n",
    "- SQL Database Tool: Query structured data\n",
    "- Retriever: Access unstructured documentation\n",
    "- Web Search: Get latest information\n",
    "\n",
    "**Scenario:** \"What were our top-selling products last quarter and what do experts say about market trends?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example setup with NEW API\n",
    "print(\"\"\"\n",
    "# Using the @tool decorator for custom retrieval tools\n",
    "from langchain.tools import tool\n",
    "\n",
    "# Create multiple vector stores\n",
    "docs_vectorstore = Chroma(..., collection_name=\"technical_docs\")\n",
    "support_vectorstore = Chroma(..., collection_name=\"customer_support\")\n",
    "code_vectorstore = Chroma(..., collection_name=\"code_examples\")\n",
    "\n",
    "# Create custom tool functions with @tool decorator\n",
    "@tool\n",
    "def search_technical_docs(query: str) -> str:\n",
    "    '''Search official technical documentation and API references.'''\n",
    "    docs = docs_vectorstore.as_retriever().invoke(query)\n",
    "    return \"\\\\n\\\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "@tool\n",
    "def search_support_tickets(query: str) -> str:\n",
    "    '''Search past customer support tickets and solutions.'''\n",
    "    docs = support_vectorstore.as_retriever().invoke(query)\n",
    "    return \"\\\\n\\\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "@tool\n",
    "def search_code_examples(query: str) -> str:\n",
    "    '''Search code examples and implementation patterns.'''\n",
    "    docs = code_vectorstore.as_retriever().invoke(query)\n",
    "    return \"\\\\n\\\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "# Create agent with NEW API - much simpler!\n",
    "multi_db_agent = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[search_technical_docs, search_support_tickets, search_code_examples, web_search_tool],\n",
    "    system_prompt=\"You are a helpful assistant that can search multiple knowledge bases.\"\n",
    ")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4: API Integration + RAG\n",
    "\n",
    "**Use Case:** Real-time data from external APIs combined with knowledge base\n",
    "\n",
    "**Tools:**\n",
    "- Weather API: Current weather data\n",
    "- Stock API: Live stock prices\n",
    "- News API: Latest news\n",
    "- Retriever: Historical context and analysis\n",
    "\n",
    "**Scenario:** \"How is the current weather affecting airline stock prices based on historical patterns?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example setup with NEW API\n",
    "print(\"\"\"\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain.tools import tool\n",
    "import requests\n",
    "\n",
    "# Connect to database\n",
    "db = SQLDatabase.from_uri(\"sqlite:///sales.db\")\n",
    "\n",
    "# Create custom tools with @tool decorator\n",
    "@tool\n",
    "def query_sales_database(sql_query: str) -> str:\n",
    "    '''Execute SQL queries on the sales database for product information, revenue, and customer data.'''\n",
    "    try:\n",
    "        result = db.run(sql_query)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return f\"Error executing query: {str(e)}\"\n",
    "\n",
    "# Create agent with NEW API\n",
    "sql_rag_agent = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[query_sales_database, knowledge_base_search, web_search_tool],\n",
    "    system_prompt='''You are a business analyst assistant. \n",
    "    Use the SQL database for quantitative data, knowledge base for product context, \n",
    "    and web search for market trends.'''\n",
    ")\n",
    "\n",
    "# Agent workflow:\n",
    "# 1. Query SQL database for sales data\n",
    "# 2. Retrieve product documentation for context\n",
    "# 3. Search web for market trends\n",
    "# 4. Synthesize comprehensive answer\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 5: Document Analysis + Web Research\n",
    "\n",
    "**Use Case:** Analyze uploaded documents with external context\n",
    "\n",
    "**Tools:**\n",
    "- PDF Retriever: Search through uploaded PDFs\n",
    "- CSV Analyzer: Analyze spreadsheet data\n",
    "- Web Search: Find related information\n",
    "- Wikipedia: Get background knowledge\n",
    "\n",
    "**Scenario:** \"Analyze this research paper and find related recent studies\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example setup with NEW API\n",
    "print(\"\"\"\n",
    "from langchain.tools import tool\n",
    "import requests\n",
    "\n",
    "# Create custom API tools with @tool decorator\n",
    "@tool\n",
    "def get_weather(location: str) -> str:\n",
    "    '''Get current weather conditions for any location.'''\n",
    "    try:\n",
    "        response = requests.get(f\"https://api.weather.com/{location}\", timeout=10)\n",
    "        response.raise_for_status()\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"Error fetching weather: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def get_stock_price(symbol: str) -> str:\n",
    "    '''Get real-time stock prices and trading data for a given stock symbol.'''\n",
    "    try:\n",
    "        response = requests.get(f\"https://api.stocks.com/{symbol}\", timeout=10)\n",
    "        response.raise_for_status()\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"Error fetching stock data: {str(e)}\"\n",
    "\n",
    "# Create agent with NEW API\n",
    "api_rag_agent = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[get_weather, get_stock_price, knowledge_base_search, web_search_tool],\n",
    "    system_prompt=\"You combine real-time API data with historical knowledge to provide insights.\"\n",
    ")\n",
    "\n",
    "# Example usage:\n",
    "# result = api_rag_agent.invoke({\n",
    "#     \"messages\": [HumanMessage(content=\"How is weather affecting airline stocks today?\")]\n",
    "# })\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 6: Hybrid Search (Dense + Sparse)\n",
    "\n",
    "**Use Case:** Combine semantic search with keyword search\n",
    "\n",
    "**Tools:**\n",
    "- Dense Retriever: Semantic similarity search (embeddings)\n",
    "- Sparse Retriever: Keyword/BM25 search\n",
    "- Reranker: Rerank results for better relevance\n",
    "\n",
    "**Benefits:**\n",
    "- Better recall (find more relevant documents)\n",
    "- Handle exact matches and semantic matches\n",
    "- Improved accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example setup with NEW API\n",
    "print(\"\"\"\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain.tools import tool\n",
    "\n",
    "# Load and process PDF\n",
    "pdf_loader = PyPDFLoader(\"research_paper.pdf\")\n",
    "pdf_docs = pdf_loader.load_and_split()\n",
    "pdf_vectorstore = Chroma.from_documents(pdf_docs, embeddings)\n",
    "pdf_retriever = pdf_vectorstore.as_retriever()\n",
    "\n",
    "# Create custom PDF search tool\n",
    "@tool\n",
    "def search_pdf_document(query: str) -> str:\n",
    "    '''Search through the uploaded PDF research paper.'''\n",
    "    docs = pdf_retriever.invoke(query)\n",
    "    return \"\\\\n\\\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "# Wikipedia tool\n",
    "wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
    "\n",
    "# Create agent with NEW API\n",
    "doc_analysis_agent = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[search_pdf_document, wikipedia, web_search_tool],\n",
    "    system_prompt=\"Analyze documents and find related research from multiple sources.\"\n",
    ")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 7: Memory-Enhanced Agentic RAG\n",
    "\n",
    "**Use Case:** Multi-turn conversations with context awareness\n",
    "\n",
    "**Components:**\n",
    "- Conversation Memory: Remember previous interactions\n",
    "- Retriever: Access knowledge base\n",
    "- Web Search: Current information\n",
    "\n",
    "**Benefits:**\n",
    "- Follow-up questions work naturally\n",
    "- Reference previous answers\n",
    "- Build on previous context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example setup with NEW API\n",
    "print(\"\"\"\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain.tools import tool\n",
    "\n",
    "# Dense retriever (semantic)\n",
    "dense_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# Sparse retriever (keyword)\n",
    "bm25_retriever = BM25Retriever.from_documents(documents)\n",
    "bm25_retriever.k = 5\n",
    "\n",
    "# Ensemble retriever (combines both)\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[dense_retriever, bm25_retriever],\n",
    "    weights=[0.5, 0.5]  # Equal weight to both methods\n",
    ")\n",
    "\n",
    "# Create hybrid search tool\n",
    "@tool\n",
    "def hybrid_search(query: str) -> str:\n",
    "    '''Search using both semantic similarity and keyword matching for better accuracy.'''\n",
    "    docs = ensemble_retriever.invoke(query)\n",
    "    return \"\\\\n\\\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "# Create agent with NEW API\n",
    "hybrid_agent = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[hybrid_search, web_search_tool],\n",
    "    system_prompt=\"Use hybrid search for comprehensive retrieval combining semantic and keyword matching.\"\n",
    ")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 7: Conversational Agentic RAG with LangGraph Persistence\n",
    "\n",
    "**Use Case:** Multi-turn conversations with context awareness\n",
    "\n",
    "**NEW in LangChain v1:** Built-in persistence through LangGraph checkpointing!\n",
    "\n",
    "**Benefits:**\n",
    "- Follow-up questions work naturally\n",
    "- Reference previous answers\n",
    "- No need for separate memory management\n",
    "- Automatic conversation state handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## What Changed in LangChain v1? Migration Guide\n",
    "\n",
    "### Old API (Deprecated) â†’ New API (Current)\n",
    "\n",
    "| Old (create_react_agent/create_tool_calling_agent) | New (create_agent) |\n",
    "|-----------------------------------------------------|---------------------|\n",
    "| Multiple imports and setup | Single import: `from langchain.agents import create_agent` |\n",
    "| Separate prompt template | Simple `system_prompt` string |\n",
    "| Create agent + Create executor (2 steps) | Single `create_agent()` call |\n",
    "| Manual memory management | Built-in persistence via LangGraph |\n",
    "| Complex streaming setup | Native `.stream()` support |\n",
    "| `agent_executor.invoke({\"input\": query})` | `agent.invoke({\"messages\": [HumanMessage(content=query)]})` |\n",
    "\n",
    "### Key Benefits of v1:\n",
    "\n",
    "âœ… **Simpler API**: Less boilerplate code\n",
    "âœ… **Built on LangGraph**: Automatic persistence, streaming, human-in-the-loop\n",
    "âœ… **Better reliability**: Improved error handling and retries\n",
    "âœ… **Tool decorator**: Clean `@tool` syntax for custom tools\n",
    "âœ… **Message-based**: Consistent message interface\n",
    "âœ… **Middleware support**: Easy customization and extension\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Conversational agent with automatic persistence\n",
    "print(\"\"\"\n",
    "# NEW LangChain v1: Memory is built-in through LangGraph!\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# Create checkpointer for conversation history\n",
    "memory = MemorySaver()\n",
    "\n",
    "# Create agent with memory support\n",
    "conversational_agent = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[knowledge_base_search, web_search_tool],\n",
    "    system_prompt=\"You are a helpful assistant with memory of our conversation.\",\n",
    "    checkpointer=memory  # Add persistence!\n",
    ")\n",
    "\n",
    "# Multi-turn conversation with thread_id\n",
    "thread_id = \"conversation-123\"\n",
    "\n",
    "# First question\n",
    "response1 = conversational_agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What is LangChain?\")]},\n",
    "    config={\"configurable\": {\"thread_id\": thread_id}}\n",
    ")\n",
    "\n",
    "# Follow-up question - agent remembers context!\n",
    "response2 = conversational_agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"How does it compare to other frameworks?\")]},\n",
    "    config={\"configurable\": {\"thread_id\": thread_id}}\n",
    ")\n",
    "\n",
    "# Agent automatically maintains conversation history!\n",
    "# No need for manual memory management like before\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways and Best Practices\n",
    "\n",
    "### 1. Tool Design (Updated for v1)\n",
    "- **Use @tool decorator**: Cleaner and more maintainable\n",
    "- **Clear docstrings**: Help agent understand when to use each tool\n",
    "- **Type hints**: Required for proper tool argument parsing\n",
    "- **Good naming**: Use descriptive, intuitive function names\n",
    "\n",
    "### 2. Prompt Engineering\n",
    "- **Use system_prompt**: Simple string instead of complex templates\n",
    "- **Tool guidelines**: Provide clear criteria for tool selection\n",
    "- **Be explicit**: Tell agent how to reason and respond\n",
    "\n",
    "### 3. Message Handling (NEW)\n",
    "- **Message format**: Use `{\"messages\": [HumanMessage(content=\"...\")]}` \n",
    "- **Access results**: Final answer in `result['messages'][-1].content`\n",
    "- **Conversation threads**: Use thread_id for multi-turn conversations\n",
    "\n",
    "### 4. Performance Optimization\n",
    "- **Chunk size**: Balance between context and precision\n",
    "- **Number of retrievals**: More isn't always better (k=3 is often good)\n",
    "- **Caching**: Cache embeddings and frequent queries\n",
    "- **Streaming**: Use `.stream()` for better user experience\n",
    "\n",
    "### 5. LangGraph Features (Built-in with v1)\n",
    "- **Persistence**: Add `checkpointer` for conversation memory\n",
    "- **Streaming**: Multiple modes (\"values\", \"updates\", \"messages\")\n",
    "- **Human-in-the-loop**: Pause for approval before actions\n",
    "- **Time travel**: Rewind and explore alternate paths\n",
    "\n",
    "### 6. Production Considerations\n",
    "- **Error handling**: Built-in retry and error handling\n",
    "- **Rate limiting**: Prevent API abuse\n",
    "- **Logging**: Use LangSmith for tracing and debugging\n",
    "- **Security**: Sanitize tool inputs and outputs\n",
    "- **Monitoring**: Track costs, latency, and success rates\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Agentic RAG with LangChain v1 represents a powerful evolution in building intelligent applications:\n",
    "\n",
    "âœ… **Simpler API**: `create_agent()` replaces complex multi-step setup\n",
    "\n",
    "âœ… **Dynamic Tool Selection**: Agent intelligently chooses the right tool for each query\n",
    "\n",
    "âœ… **Multi-Source Information**: Combines vector DB, web search, APIs, and more\n",
    "\n",
    "âœ… **Built on LangGraph**: Automatic persistence, streaming, and reliability\n",
    "\n",
    "âœ… **Better Developer Experience**: Less boilerplate, clearer patterns\n",
    "\n",
    "âœ… **Production-Ready**: Built-in error handling, retries, and monitoring support\n",
    "\n",
    "### Next Steps:\n",
    "1. Experiment with different tool combinations for your use case\n",
    "2. Add custom tools using the `@tool` decorator\n",
    "3. Implement conversation persistence with checkpointers\n",
    "4. Use LangSmith for tracing and evaluation\n",
    "5. Deploy with proper monitoring and rate limiting\n",
    "\n",
    "### Resources:\n",
    "- **LangChain Docs**: https://docs.langchain.com\n",
    "- **LangGraph Docs**: https://langchain-ai.github.io/langgraph/\n",
    "- **LangSmith**: https://smith.langchain.com (for tracing and evaluation)\n",
    "- **Community**: https://github.com/langchain-ai/langchain\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Building with Agentic RAG! ğŸš€**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangchainTrainingnew",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
